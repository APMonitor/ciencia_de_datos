{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparación de Datos\n",
    "\n",
    "[Playlist de Ciencia de Datos en castellano](https://www.youtube.com/watch?v=tBfGYKITno8&list=PLLBUgWXdTBDg1Qgmwt4jKtVn9BWh5-zgy)\n",
    "[![Ciencia de Datos en Python](https://img1.wsimg.com/isteam/ip/aab852a2-7b1f-49c0-92af-9206f2ec6a75/6-0001.png/:/rs=w:1160,h:653)](https://www.youtube.com/watch?v=tBfGYKITno8&list=PLLBUgWXdTBDg1Qgmwt4jKtVn9BWh5-zgy \"Python Data Science\")\n",
    "\n",
    "Gran parte del trabajo en Ciencia de Datos y Aprendizaje Automático (Machine Learning) consiste en obtener datos limpios y en la forma correcta. Esto puede incluir limpieza de datos para eliminar valores atípicos o mala información, escalado para algoritmos de aprendizaje automático o machine learning, división en grupos de entrenamiento y prueba, y enumeración de datos tipo \"string\". Todo esto debe suceder antes de la regresión, clasificación u otro entrenamiento aplicado al modelo. Afortunadamente, existen funciones que nos ayudan a automatizar la preparación de los datos.\n",
    "\n",
    "![idea](https://apmonitor.com/che263/uploads/Begin_Python/idea.png)\n",
    "\n",
    "### Generar Datos de Muestra\n",
    "\n",
    "Ejecuta la siguiente celda para generar datos de muestra dañados con NaN (not a number) y valores atípicos que son puntos de datos erróneos que están muy por fuera de la tendencia esperada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1)\n",
    "n = 100\n",
    "tt = np.linspace(0,n-1,n)\n",
    "x = np.random.rand(n)+10+np.sqrt(tt)\n",
    "y = np.random.normal(10,x*0.01,n)\n",
    "x[1] = np.nan; y[2] = np.nan  # 2 NaN (not a number)\n",
    "for i in range(3):            # añade 3 valores atípicos (datos malos)\n",
    "    ri = np.random.randint(0,n)\n",
    "    x[ri] += np.random.rand()*100\n",
    "data = pd.DataFrame(np.vstack((tt,x,y)).T,\\\n",
    "                    columns=['time','x','y'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![analyze](https://apmonitor.com/che263/uploads/Begin_Python/analyze.png)\n",
    "\n",
    "### Visualización de los Datos\n",
    "\n",
    "Los valores atípicos se muestran en un gráfico semi-log. Los valores `NaN` no se muestran en la gráfica y son puntos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.semilogy(tt,x,'r.',label='x')\n",
    "plt.semilogy(tt,y,'b.',label='y')\n",
    "plt.legend(); plt.xlabel('tiempo')\n",
    "plt.text(50,60,'Valores atípicos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![idea](https://apmonitor.com/che263/uploads/Begin_Python/idea.png)\n",
    "\n",
    "### Eliminar Valores Atípicos y Datos Erróneos\n",
    "\n",
    "Los valores NaN se eliminan con `numpy` identificando filas `ix` que contienen `NaN`. A continuación, las filas se eliminan con `z=z[~iz]` donde `~` Es un operador `not`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([[      1,      2],\n",
    "              [ np.nan,      3],\n",
    "              [      4, np.nan],\n",
    "              [      5,      6]])\n",
    "iz = np.any(np.isnan(z), axis=1)\n",
    "print(~iz)\n",
    "z = z[~iz]\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `dropna` es un comando que quita filas `NaN` en un `pandas` `DataFrame`. La fila 1 y 2 son removidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar cualquier fila con valores erróneos (NaN)\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias técnicas gráficas para detectar valores atípicos. Un diagrama de caja o histograma muestra los 3 puntos periféricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data['x'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una prueba de Grubbs u [otra medida estadística](https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba) puede detectar valores atípicos. La prueba de Grubbs asume datos univariados, normalmente distribuidos y está destinada a detectar solo un valor atípico. En la práctica, muchos valores atípicos se eliminan al remover puntos que violan un límite de cambio, o límites superior/inferior. El enunciado `data[data['x']<30]` mantiene las filas donde x es menor a 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['x']<30]\n",
    "plt.boxplot(data['x'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![expert](https://apmonitor.com/che263/uploads/Begin_Python/expert.png)\n",
    "\n",
    "### Actividad con Tiempo\n",
    "\n",
    "Sin mirar tu reloj, ejecuta la siguiente celda para registrar intervalos de 1 segundo durante 10 segundos. Cuando ejecutes la celda, presiona `Enter` cada vez que creas que ha pasado 1 segundo. Después de recopilar los datos, utiliza un diagrama de caja para identificar cualquier punto de datos en `tsec` que son valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "tsec = []\n",
    "input('Presiona \"Enter\" para grabar intervalos de 1 segundo'); t = time.time()\n",
    "for i in range(10):\n",
    "    clear_output(); input('Presiona \"Enter\": ' + str(i+1))\n",
    "    tsec.append(time.time()-t); t = time.time()\n",
    "clear_output(); print('Completo. Agrega un diagrama de caja para identificar valores atípicos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar un diagrama de caja para identificar valores atípicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![idea](https://apmonitor.com/che263/uploads/Begin_Python/idea.png)\n",
    "\n",
    "### Escala de Datos\n",
    "\n",
    "La librería `sklearn` tiene un módulo de pre-procesamiento (`preprocessing`) para implementar métodos de escalado estándar. El `StandardScalar` se muestra a continuación. Cada columna se normaliza a una media cero y una desviación estándar de uno. Los métodos de escalado comunes `fit_transform(X)` para ajuste y `transform(X)` transformación basado en otro ajuste, y `inverse_transform(Xs)` para volver a escalar a la representación original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "ds = s.fit_transform(data)\n",
    "print(ds[0:5]) # imprime 5 filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor `ds` se devuelve como un array `numpy` así que tenemos que convertirlo de nuevo a `pandas` `DataFrame`, reutilizando los nombres de columna `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.DataFrame(ds,columns=data.columns)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![idea](https://apmonitor.com/che263/uploads/Begin_Python/idea.png)\n",
    "\n",
    "### Dividir Datos\n",
    "\n",
    "Los datos se dividen en grupos de entrenamiento y prueba para separar una fracción de las filas para evaluar modelos de clasificación o regresión. Una división típica es 80% para entrenamiento y 20% para pruebas, aunque el rango depende de la cantidad de datos disponibles y del objetivo del estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide = int(len(ds)*0.8)\n",
    "train = ds[0:divide]\n",
    "test = ds[divide:]\n",
    "print(len(train),len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `train_test_split` es una función de `sklearn` que tiene el propósito específico de dividir los datos en grupos de entrenamiento y prueba. Existen opciones como `shuffle=True` para aleatorizar la selección en cada conjunto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(ds, test_size=0.2, shuffle=True)\n",
    "print(len(train),len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad con el TCLab\n",
    "\n",
    "![expert](https://apmonitor.com/che263/uploads/Begin_Python/expert.png)\n",
    "\n",
    "### Datos con Valores Erróneos y Atípicos\n",
    "\n",
    "Genera un nuevo archivo de datos con algunos datos incorrectos insertados aleatoriamente (3 minutos) o lee el archivo de datos de [un link en la web](https://apmonitor.com/do/uploads/Main/tclab_bad_data.txt) con el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tclab, time, csv\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    with tclab.TCLab() as lab:\n",
    "        with open('05-tclab.csv',mode='w',newline='') as f:\n",
    "            cw = csv.writer(f)\n",
    "            cw.writerow(['Time','Q1','Q2','T1','T2'])\n",
    "            print('t Q1 Q2 T1    T2')\n",
    "            for t in range(180):\n",
    "                T1 = lab.T1; T2 = lab.T2\n",
    "                # insertar valores malos\n",
    "                bad = np.random.randint(0,30)\n",
    "                T1=np.nan if bad==10 else T1\n",
    "                T2=np.nan if bad==15 else T2\n",
    "                # insertar número aleatorio (potencial valor atípico)\n",
    "                outlier = np.random.randint(-40,150)\n",
    "                T1=outlier if bad==20 else T1\n",
    "                T2=outlier if bad==25 else T2\n",
    "                # cambiar el calentador\n",
    "                if t%30==0:\n",
    "                    Q1 = np.random.randint(0,81)\n",
    "                    Q2 = np.random.randint(0,81)\n",
    "                    lab.Q1(Q1); lab.Q2(Q2)\n",
    "                cw.writerow([t,Q1,Q2,T1,T2])\n",
    "                if t%10==0:\n",
    "                    print(t,Q1,Q2,T1,T2)\n",
    "                time.sleep(1)\n",
    "            data5=pd.read_csv('05-tclab.csv')\n",
    "except:\n",
    "    print('Conectar el TCLab para generar nuevos datos')\n",
    "    print('Importar datos de un repositorio en línea')\n",
    "    url = 'http://apmonitor.com/do/uploads/Main/tclab_bad_data.txt'\n",
    "    data5=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar, Escalar y Dividir Datos\n",
    "\n",
    "Después de generar e importar `data5`, eliminar filas con valores `NaN` o valores atípicos en las columnas `T1` o `T2`. Escala los datos con `StandardScalar` en `scikit`. Divide los datos en grupos de entrenamiento (80%) y prueba (20%).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
